{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b5dd28-1e74-439b-bc19-ab76bfb2f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: 03_feature_extraction.ipynb\n",
    "\n",
    "# OBJECTIVES\n",
    "# modularize HOG, edge detection, and raw pixel features \n",
    "# allow defining and testing multiple feature combinations \n",
    "# optionally apply PCA per combo\n",
    "# save features and labels for model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e6c9259-22b5-4e28-bb3b-5e3ea48c2b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib # for saving features \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d41a30ef-3945-45dc-8fb4-aa9a97c39c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths \n",
    "INPUT_ROOT = \"../data/processed/NEU-DET\"\n",
    "OUTPUT_ROOT = \"../data/features/NEU-DET\"\n",
    "SPLITS = [\"train\", \"validation\"]\n",
    "IMAGE_SIZE = (128, 128) # should match the preprocessing step\n",
    "PCA_COMPONENTS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f9dfbf-a2a4-4809-bdc6-879342792c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature combination recipes\n",
    "# FIXED: hog was defined twice\n",
    "feature_combos = {\n",
    "    \"hog\": [\"hog\"],\n",
    "    \"edge\": [\"edge\"],\n",
    "    \"raw\": [\"raw\"],\n",
    "    \"hog_edge\": [\"hog\", \"edge\"],\n",
    "    \"hog_pca\": [\"hog\", \"pca\"],\n",
    "    \"hog_edge_pca\": [\"hog\", \"edge\", \"pca\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b7534c-3624-416f-935c-68e04875aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction functions \n",
    "def extract_hog(img): \n",
    "    return hog(img,\n",
    "        orientations=9, \n",
    "               pixels_per_cell=(8, 8), \n",
    "               cells_per_block=(2, 2), \n",
    "               block_norm=\"L2-Hys\")\n",
    "\n",
    "def extract_edge(img): \n",
    "    edge_map = cv2.Canny(img, 100, 200) \n",
    "    return edge_map.flatten() / 255.0\n",
    "\n",
    "def extract_raw(img): \n",
    "    return img.flatten() / 255.0\n",
    "\n",
    "# combine features based on the combo setting\n",
    "def extract_features(img, combo): \n",
    "    feats = []\n",
    "    if \"hog\" in combo: \n",
    "        feats.append(extract_hog(img))\n",
    "    if \"edge\" in combo: \n",
    "        feats.append(extract_edge(img))\n",
    "    if \"raw\" in combo: \n",
    "        feats.append(extract_raw(img))\n",
    "    return np.concatenate(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79cfe33b-e324-4708-8de5-a05f6c0e415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Extracting features for combo: hog\n",
      "   ‚è≥ Processing train (1440 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1440/1440 [00:03<00:00, 405.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ train feature shape: (1440, 8100)\n",
      "   ‚è≥ Processing validation (360 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 360/360 [00:00<00:00, 397.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ validation feature shape: (360, 8100)\n",
      "   Applying StandardScaler...\n",
      "   üíæ Saved combo 'hog' to ../data/features/NEU-DET/hog\n",
      "\n",
      "üîÑ Extracting features for combo: edge\n",
      "   ‚è≥ Processing train (1440 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1440/1440 [00:00<00:00, 4076.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ train feature shape: (1440, 16384)\n",
      "   ‚è≥ Processing validation (360 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 360/360 [00:00<00:00, 4279.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ validation feature shape: (360, 16384)\n",
      "   Applying StandardScaler...\n",
      "   üíæ Saved combo 'edge' to ../data/features/NEU-DET/edge\n",
      "\n",
      "üîÑ Extracting features for combo: raw\n",
      "   ‚è≥ Processing train (1440 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1440/1440 [00:00<00:00, 8328.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ train feature shape: (1440, 16384)\n",
      "   ‚è≥ Processing validation (360 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 360/360 [00:00<00:00, 8193.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ validation feature shape: (360, 16384)\n",
      "   Applying StandardScaler...\n",
      "   üíæ Saved combo 'raw' to ../data/features/NEU-DET/raw\n",
      "\n",
      "üîÑ Extracting features for combo: hog_edge\n",
      "   ‚è≥ Processing train (1440 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1440/1440 [00:03<00:00, 377.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ train feature shape: (1440, 24484)\n",
      "   ‚è≥ Processing validation (360 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 360/360 [00:00<00:00, 371.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ validation feature shape: (360, 24484)\n",
      "   Applying StandardScaler...\n",
      "   üíæ Saved combo 'hog_edge' to ../data/features/NEU-DET/hog_edge\n",
      "\n",
      "üîÑ Extracting features for combo: hog_pca\n",
      "   ‚è≥ Processing train (1440 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1440/1440 [00:03<00:00, 401.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ train feature shape: (1440, 8100)\n",
      "   ‚è≥ Processing validation (360 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 360/360 [00:00<00:00, 396.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ validation feature shape: (360, 8100)\n",
      "   Applying StandardScaler...\n",
      "   Applying PCA...\n",
      "   üíæ Saved PCA model to ../data/features/NEU-DET/hog_pca/pca_model.pkl\n",
      "   üíæ Saved combo 'hog_pca' to ../data/features/NEU-DET/hog_pca\n",
      "\n",
      "üîÑ Extracting features for combo: hog_edge_pca\n",
      "   ‚è≥ Processing train (1440 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1440/1440 [00:03<00:00, 363.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ train feature shape: (1440, 24484)\n",
      "   ‚è≥ Processing validation (360 images...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 360/360 [00:01<00:00, 359.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ validation feature shape: (360, 24484)\n",
      "   Applying StandardScaler...\n",
      "   Applying PCA...\n",
      "   üíæ Saved PCA model to ../data/features/NEU-DET/hog_edge_pca/pca_model.pkl\n",
      "   üíæ Saved combo 'hog_edge_pca' to ../data/features/NEU-DET/hog_edge_pca\n"
     ]
    }
   ],
   "source": [
    "# now loop over each combination\n",
    "for combo_name, combo_parts in feature_combos.items(): \n",
    "    print(f\"\\nüîÑ Extracting features for combo: {combo_name}\")\n",
    "\n",
    "    all_features = {}\n",
    "    all_labels = {}\n",
    "\n",
    "    for split in SPLITS: \n",
    "        input_dir = os.path.join(INPUT_ROOT, split, \"images\")\n",
    "        image_paths = glob.glob(os.path.join(input_dir, \"**\", \"*.jpg\"), recursive=True)\n",
    "\n",
    "        features = []\n",
    "        labels = []\n",
    "\n",
    "        print(f\"   ‚è≥ Processing {split} ({len(image_paths)} images...)\")\n",
    "        for path in tqdm(image_paths): \n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None: \n",
    "                print(f\"‚ùå Could not load image: {path}\")\n",
    "                continue\n",
    "\n",
    "            try: \n",
    "                feat = extract_features(img, combo_parts)\n",
    "                label = os.path.basename(os.path.dirname(path))\n",
    "                features.append(feat)\n",
    "                labels.append(label)\n",
    "            except Exception as e: \n",
    "                print(f\"‚ùå Error processing {path} in combo '{combo_name}': {e}\")\n",
    "\n",
    "        all_features[split] = np.array(features)\n",
    "        all_labels[split] = np.array(labels)\n",
    "        print(f\"   ‚úÖ {split} feature shape: {all_features[split].shape}\")\n",
    "\n",
    "    # BUG FIX: ensure output_dir is defined before saving PCA or features \n",
    "    output_dir = os.path.join(OUTPUT_ROOT, combo_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # OPTIONAL: add standardization or normalization before applying PCA\n",
    "    print(\"   Applying StandardScaler...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(all_features[\"train\"])\n",
    "    X_val_scaled = scaler.transform(all_features[\"validation\"])\n",
    "\n",
    "    all_features[\"train\"] = X_train_scaled\n",
    "    all_features[\"validation\"] = X_val_scaled\n",
    "    \n",
    "    # OPTIONAL: apply PCA\n",
    "    if \"pca\" in combo_parts: \n",
    "        print(f\"   Applying PCA...\")\n",
    "        pca = PCA(n_components=PCA_COMPONENTS)\n",
    "        X_train_pca = pca.fit_transform(all_features[\"train\"])\n",
    "        X_val_pca = pca.transform(all_features[\"validation\"])\n",
    "\n",
    "        all_features[\"train\"] = X_train_pca\n",
    "        all_features[\"validation\"] = X_val_pca\n",
    "\n",
    "        # save PCA model\n",
    "        joblib.dump(pca, os.path.join(output_dir, \"pca_model.pkl\"))\n",
    "        print(f\"   üíæ Saved PCA model to {output_dir}/pca_model.pkl\")\n",
    "    else: \n",
    "        pca = None\n",
    "\n",
    "    # save outputs\n",
    "    output_dir = os.path.join(OUTPUT_ROOT, combo_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    joblib.dump(all_features[\"train\"], os.path.join(output_dir, f\"X_train.pkl\"))\n",
    "    joblib.dump(all_labels[\"train\"], os.path.join(output_dir, f\"y_train.pkl\"))\n",
    "    joblib.dump(all_features[\"validation\"], os.path.join(output_dir, f\"X_validation.pkl\"))\n",
    "    joblib.dump(all_labels[\"validation\"], os.path.join(output_dir, f\"y_validation.pkl\"))\n",
    "\n",
    "    joblib.dump(scaler, os.path.join(output_dir, \"scaler.pkl\"))\n",
    "    \n",
    "    print(f\"   üíæ Saved combo '{combo_name}' to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7514c74f-92c9-47c4-a1ba-a689eaf6b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded combo:  hog_edge_pca\n",
      "Feature shape:  (1440, 100)\n",
      "Label sample:  ['pitted_surface' 'pitted_surface' 'pitted_surface' 'pitted_surface'\n",
      " 'pitted_surface' 'pitted_surface']\n"
     ]
    }
   ],
   "source": [
    "# sanity check \n",
    "combo_to_check = \"hog_edge_pca\"\n",
    "combo_path = os.path.join(OUTPUT_ROOT, combo_to_check)\n",
    "\n",
    "X_train = joblib.load(os.path.join(combo_path, \"X_train.pkl\"))\n",
    "y_train = joblib.load(os.path.join(combo_path, \"y_train.pkl\"))\n",
    "\n",
    "print(\"Loaded combo: \", combo_to_check)\n",
    "print(\"Feature shape: \", X_train.shape)\n",
    "print(\"Label sample: \", y_train[:6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
